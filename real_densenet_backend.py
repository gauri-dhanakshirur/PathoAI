# -*- coding: utf-8 -*-
"""Real DenseNet Backend

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11J2FCV-rX838DwouI4ucOWealLfAsp8F
"""

!pip install fastapi uvicorn python-multipart tensorflow pillow opencv-python-headless nest_asyncio
!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb
!dpkg -i cloudflared-linux-amd64.deb

import nest_asyncio
import uvicorn
from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import tensorflow as tf
import numpy as np
from PIL import Image
import io
import base64
import cv2
import threading

# 1. Apply the fix for the 'asyncio.run()' error
nest_asyncio.apply()

app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

# 2. Load and Warm up the Model
MODEL_PATH = '/content/best_densenet_model.h5'
print("Loading Model...")
model = tf.keras.models.load_model(MODEL_PATH)

print("Warming up layers...")
dummy_input = np.zeros((1, 96, 96, 3), dtype='float32')
model(dummy_input)

# Find Grad-CAM layer
last_conv_layer_name = None
for layer in reversed(model.layers):
    try:
        if len(layer.output.shape) == 4:
            last_conv_layer_name = layer.name
            break
    except: continue

def make_gradcam(img_array, model, layer_name):
    gm = tf.keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.output])
    with tf.GradientTape() as tape:
        conv_out, preds = gm(img_array)
        loss = preds[:, tf.argmax(preds[0])]
    grads = tape.gradient(loss, conv_out)
    pooled = tf.reduce_mean(grads, axis=(0, 1, 2))
    heatmap = conv_out[0] @ pooled[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-10)
    return heatmap.numpy()

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        data = await file.read()
        # Shashwati Specs: 96x96, 1/255 scale
        img = Image.open(io.BytesIO(data)).convert('RGB').resize((96, 96))
        x = np.expand_dims(np.array(img).astype('float32') / 255.0, axis=0)

        preds = model.predict(x)
        score = float(preds[0][0])

        # Shashwati Specs: Threshold 0.31
        label = "Metastatic" if score > 0.31 else "Normal"
        conf = score if label == "Metastatic" else (1 - score)

        heatmap = make_gradcam(x, model, last_conv_layer_name)
        heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)
        heatmap = cv2.resize(heatmap, (400, 400))
        _, b = cv2.imencode('.png', cv2.cvtColor(heatmap, cv2.COLOR_RGB2BGR))

        return {
            "status": "success", "prediction": label, "confidence": f"{conf * 100:.2f}%",
            "heatmap": f"data:image/png;base64,{base64.b64encode(b).decode()}",
            "message": f"Inference complete. Tissue classified as {label}."
        }
    except Exception as e:
        return {"status": "error", "message": str(e)}

# 3. Start Server in a Thread (so Colab doesn't block)
def run_server():
    uvicorn.run(app, host="0.0.0.0", port=8000)

print("Starting AI Server...")
threading.Thread(target=run_server, daemon=True).start()

import time
time.sleep(2) # Wait for server thread to settle
!cloudflared tunnel --url http://127.0.0.1:8000